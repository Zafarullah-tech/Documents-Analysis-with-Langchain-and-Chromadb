# Documents-Analysis-with-Langchain-and-Chromadb
Hereâ€™s a clear, professional **README.md** file for your LangChain + ChromaDB project ğŸ‘‡

---

```markdown
# ğŸ§  PDF Knowledge Search using LangChain, Hugging Face & ChromaDB

This project demonstrates how to **extract**, **embed**, and **query** knowledge from a PDF document using **LangChain**, **Hugging Face sentence embeddings**, and a **local Chroma vector database**.

---

## ğŸš€ Features
âœ… Load and process any PDF document  
âœ… Automatically split large text into smaller chunks  
âœ… Create embeddings using Hugging Face models  
âœ… Store embeddings locally in ChromaDB  
âœ… Perform semantic similarity search (ask questions about the PDF!)  

---

## ğŸ—ï¸ Project Structure
```

ğŸ“ project/
â”‚
â”œâ”€â”€ main.py                # Your Python script (the code below)
â”œâ”€â”€ chroma_db/             # Local vector database (auto-created)
â”œâ”€â”€ requirements.txt       # Required dependencies
â””â”€â”€ README.md              # Documentation (this file)

````

---

## âš™ï¸ Installation

### 1ï¸âƒ£ Clone or download this repository
```bash
git clone https://github.com/your-username/pdf-knowledge-search.git
cd pdf-knowledge-search
````

### 2ï¸âƒ£ Create and activate a virtual environment (optional but recommended)

```bash
python -m venv venv
venv\Scripts\activate       # On Windows
# OR
source venv/bin/activate    # On macOS/Linux
```

### 3ï¸âƒ£ Install dependencies

Create a `requirements.txt` file with the following packages:

```text
langchain
langchain-community
langchain-huggingface
langchain-text-splitters
chromadb
pypdf
sentence-transformers
```

Then install them:

```bash
pip install -r requirements.txt
```

---

## ğŸ“„ How It Works

### Step 1ï¸âƒ£ â€” Import Libraries

We use LangChainâ€™s document loaders, text splitters, embeddings, and vector stores.

```python
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma
```

---

### Step 2ï¸âƒ£ â€” Load the PDF

Use the `PyPDFLoader` to read your document.

```python
pdf_path = r"C:\Users\Zafrullah Khan\Downloads\Generative ai and chat boat\waziristan.pdf"
loader = PyPDFLoader(pdf_path)
documents = loader.load()
```

---

### Step 3ï¸âƒ£ â€” Split Text into Chunks

Large PDFs are divided into manageable chunks for better embedding performance.

```python
splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)
texts = splitter.split_documents(documents)
```

---

### Step 4ï¸âƒ£ â€” Create Text Embeddings

Convert text chunks into vector representations using Hugging Face embeddings.

```python
embeddings = HuggingFaceEmbeddings(model_name="sentence-transformers/all-MiniLM-L6-v2")
```

---

### Step 5ï¸âƒ£ â€” Store in ChromaDB

Save all embeddings locally in a **persistent vector database**.

```python
vectorstore = Chroma.from_documents(texts, embeddings, persist_directory="chroma_db")
```

---

### Step 6ï¸âƒ£ â€” Query the Knowledge Base

Ask natural language questions to find relevant sections.

```python
query = "what is this document about?"
results = vectorstore.similarity_search(query, k=3)
```

---

### Step 7ï¸âƒ£ â€” Display Results

Print the top 3 most relevant chunks.

```python
print("\n Top 3 relevant chunks:\n")
for i, res in enumerate(results, 1):
    print(f"Result ({i}):\n{res.page_content[:300]}...\n")
```

---

## ğŸ§© Example Output

```
Top 3 relevant chunks:

Result (1):
The document discusses the historical background and development of Waziristan, focusing on its geography and tribal system...

Result (2):
Waziristanâ€™s role in regional politics and its strategic importance are examined in relation to the broader South Asian context...
```

---

## ğŸ’¡ Notes

* Always use **raw strings (r"â€¦")** for file paths on Windows.
* The **`chroma_db/`** folder is auto-created for persistent storage.
* You can replace the Hugging Face model with any other embedding model (e.g., `all-mpnet-base-v2`).

---

## ğŸ§° Future Improvements

* Add a **Flask/Streamlit UI** for interactive chat-based queries.
* Support **multiple PDFs** and merged knowledge bases.
* Integrate **LLMs** (e.g., Gemini, GPT, or Ollama) for richer answers.

---

## ğŸ§‘â€ğŸ’» Author

**Zafarullah Khan**
ğŸ“š AI Student | ğŸ’¬ Tech Enthusiast | ğŸ’¡ Learning LangChain & Generative AI

---

## ğŸªª License

This project is open-source under the [MIT License](https://opensource.org/licenses/MIT).

```

---

Would you like me to make this README more **beginner-friendly with extra comments and emojis**, or keep it **professional (GitHub-style)**?
```
